---
layout: post
title: "hdfs数据负载均衡"
tags: [大数据, hadoop]
---
### 摘要
Hadoop集群使用久了,各个节点上的数据会变得不均衡,多的达到70,80%,少的就10,20%.
<!--excerpt-->
### 节点之间负载均衡
##### 对hdfs负载设置均衡
```shell
hdfs dfsadmin -setBalancerBandwidth 67108864 # 设置为64M，
# 或 hdfs dfsadmin -setBalancerBandwidth 134217728 # 设置为128M，
```
##### 修改默认balancer的threshold
默认balancer的threshold为10%，即各个节点存储使用率偏差不超过10%，我们可将其设置为5%
```shell
start-balancer.sh -threshold 5
# 或 start-balancer.sh –t 5%
```
**注意** 运行start-balancer.sh -threshold 5和使用hdfs balancer -threshold 5是一样的
##### 参考地址
[https://bbs.aliyun.com/detail/335179.html?page=e](https://bbs.aliyun.com/detail/335179.html?page=e)
### 各节点的磁盘之间负载均衡
##### 参考地址
[https://blog.csdn.net/lcg910978041/article/details/52601540](https://blog.csdn.net/lcg910978041/article/details/52601540)
